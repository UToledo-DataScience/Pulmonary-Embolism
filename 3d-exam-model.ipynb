{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009122,
     "end_time": "2020-10-21T22:25:54.169002",
     "exception": false,
     "start_time": "2020-10-21T22:25:54.159880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acknowledgements\n",
    "https://www.kaggle.com/allunia/pulmonary-dicom-preprocessing - DICOM preprocessing\n",
    "\n",
    "https://www.kaggle.com/seraphwedd18/pe-detection-with-keras-model-creation - DICOM preprocessing\n",
    "\n",
    "https://www.kaggle.com/redwankarimsony/rsna-str-pe-gradient-sigmoid-windowing/comments - DICOM windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-21T22:25:54.192638Z",
     "iopub.status.busy": "2020-10-21T22:25:54.191904Z",
     "iopub.status.idle": "2020-10-21T22:26:02.807392Z",
     "shell.execute_reply": "2020-10-21T22:26:02.805591Z"
    },
    "papermill": {
     "duration": 8.629926,
     "end_time": "2020-10-21T22:26:02.807528",
     "exception": false,
     "start_time": "2020-10-21T22:25:54.177602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import vtk\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from random import shuffle, sample, randrange\n",
    "from vtk.util import numpy_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:02.841467Z",
     "iopub.status.busy": "2020-10-21T22:26:02.835557Z",
     "iopub.status.idle": "2020-10-21T22:26:05.753865Z",
     "shell.execute_reply": "2020-10-21T22:26:05.752765Z"
    },
    "papermill": {
     "duration": 2.935474,
     "end_time": "2020-10-21T22:26:05.753985",
     "exception": false,
     "start_time": "2020-10-21T22:26:02.818511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../input/rsna-str-pulmonary-embolism-detection\")\n",
    "TRAIN_ROOT = DATA_ROOT/\"train\"\n",
    "\n",
    "MAX_IMAGES = 250000\n",
    "TRAIN_STEPS = 5000\n",
    "IMAGE_RESOLUTION = (256, 256)\n",
    "\n",
    "train_csv = pd.read_csv(DATA_ROOT/\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:05.786866Z",
     "iopub.status.busy": "2020-10-21T22:26:05.785060Z",
     "iopub.status.idle": "2020-10-21T22:26:05.787625Z",
     "shell.execute_reply": "2020-10-21T22:26:05.788078Z"
    },
    "papermill": {
     "duration": 0.025527,
     "end_time": "2020-10-21T22:26:05.788209",
     "exception": false,
     "start_time": "2020-10-21T22:26:05.762682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = vtk.vtkDICOMImageReader()\n",
    "def get_img(path):\n",
    "    reader.SetFileName(path)\n",
    "    reader.Update()\n",
    "    _extent = reader.GetDataExtent()\n",
    "    ConstPixelDims = [_extent[1]-_extent[0]+1, _extent[3]-_extent[2]+1, _extent[5]-_extent[4]+1]\n",
    "\n",
    "    ConstPixelSpacing = reader.GetPixelSpacing()\n",
    "    \n",
    "    dcm_fields = [reader.GetRescaleSlope(), reader.GetRescaleOffset()]\n",
    "    \n",
    "    imageData = reader.GetOutput()\n",
    "    pointData = imageData.GetPointData()\n",
    "    arrayData = pointData.GetArray(0)\n",
    "    ArrayDicom = numpy_support.vtk_to_numpy(arrayData)\n",
    "    ArrayDicom = ArrayDicom.reshape(ConstPixelDims, order='F')\n",
    "    ArrayDicom = cv2.resize(ArrayDicom, IMAGE_RESOLUTION)\n",
    "    return ArrayDicom, dcm_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:05.823844Z",
     "iopub.status.busy": "2020-10-21T22:26:05.822603Z",
     "iopub.status.idle": "2020-10-21T22:26:05.825054Z",
     "shell.execute_reply": "2020-10-21T22:26:05.825540Z"
    },
    "papermill": {
     "duration": 0.028834,
     "end_time": "2020-10-21T22:26:05.825646",
     "exception": false,
     "start_time": "2020-10-21T22:26:05.796812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lung_window(img, dcm_fields):\n",
    "    width = 1250\n",
    "    length = -600\n",
    "    window_min = length - (width/2)\n",
    "    window_max = length + (width/2)\n",
    "    slope, intercept = dcm_fields\n",
    "    #img += np.abs(np.min(img))\n",
    "    img = img * slope + intercept\n",
    "    img[img < window_min] = window_min\n",
    "    img[img > window_max] = window_max\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    #print(np.min(img), np.max(img))\n",
    "    return img\n",
    "\n",
    "def map_to_gradient(grey_img):\n",
    "    rainbow_img = np.zeros((grey_img.shape[0], grey_img.shape[1], 3))\n",
    "    rainbow_img[:, :, 0] = np.clip(4 * grey_img - 2, 0, 1.0) * (grey_img > 0) * (grey_img <= 1.0)\n",
    "    rainbow_img[:, :, 1] =  np.clip(4 * grey_img * (grey_img <=0.75), 0,1) + np.clip((-4*grey_img + 4) * (grey_img > 0.75), 0, 1)\n",
    "    rainbow_img[:, :, 2] = np.clip(-4 * grey_img + 2, 0, 1.0) * (grey_img > 0) * (grey_img <= 1.0)\n",
    "    return rainbow_img\n",
    "\n",
    "def rainbow_window(img, dcm_fields):\n",
    "    grey_img = lung_window(img, dcm_fields)\n",
    "    return map_to_gradient(grey_img)\n",
    "\n",
    "def all_channels_window(img, dcm_fields):\n",
    "    grey_img = lung_window(img, dcm_fields) * 3.0\n",
    "    all_chan_img = np.zeros((grey_img.shape[0], grey_img.shape[1], 3))\n",
    "    all_chan_img[:, :, 2] = np.clip(grey_img, 0.0, 1.0)\n",
    "    all_chan_img[:, :, 0] = np.clip(grey_img - 1.0, 0.0, 1.0)\n",
    "    all_chan_img[:, :, 1] = np.clip(grey_img - 2.0, 0.0, 1.0)\n",
    "    return all_chan_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:05.852394Z",
     "iopub.status.busy": "2020-10-21T22:26:05.851677Z",
     "iopub.status.idle": "2020-10-21T22:26:06.020424Z",
     "shell.execute_reply": "2020-10-21T22:26:06.019288Z"
    },
    "papermill": {
     "duration": 0.185176,
     "end_time": "2020-10-21T22:26:06.020542",
     "exception": false,
     "start_time": "2020-10-21T22:26:05.835366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "studies = os.listdir(TRAIN_ROOT)\n",
    "#studies = studies[:len(studies)//16]\n",
    "\n",
    "func = lambda x: int((2**15 + x)*(255/2**16))\n",
    "int16_to_uint8 = np.vectorize(func)\n",
    "\n",
    "def load_scans(dcm_path):\n",
    "    # otherwise we sort by ImagePositionPatient (z-coordinate) or by SliceLocation\n",
    "    slices = []\n",
    "    fields = []\n",
    "    for file in os.listdir(dcm_path):\n",
    "        image, dcm_fields = get_img(dcm_path + \"/\" + file)\n",
    "        image = rainbow_window(image, dcm_fields)\n",
    "        slices.append(image)\n",
    "        fields.append(dcm_fields)\n",
    "\n",
    "    return slices, fields\n",
    "\n",
    "def filter_scanner(raw_pixelarrays):\n",
    "    # in OSIC we find outside-scanner-regions with raw-values of -2000. \n",
    "    # Let's threshold between air (0) and this default (-2000) using -1000\n",
    "    raw_pixelarrays[raw_pixelarrays <= -1000] = -1000\n",
    "    return raw_pixelarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:06.054228Z",
     "iopub.status.busy": "2020-10-21T22:26:06.052784Z",
     "iopub.status.idle": "2020-10-21T22:26:06.334750Z",
     "shell.execute_reply": "2020-10-21T22:26:06.334138Z"
    },
    "papermill": {
     "duration": 0.30412,
     "end_time": "2020-10-21T22:26:06.334856",
     "exception": false,
     "start_time": "2020-10-21T22:26:06.030736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_labels = train_csv[['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID', 'pe_present_on_image']]\n",
    "\n",
    "exam_label_columns = ['StudyInstanceUID', 'negative_exam_for_pe', 'rv_lv_ratio_gte_1',\n",
    "                      'rv_lv_ratio_lt_1', 'leftsided_pe', 'chronic_pe', 'rightsided_pe',\n",
    "                      'acute_and_chronic_pe', 'central_pe', 'indeterminate']\n",
    "exam_labels = train_csv[exam_label_columns].drop_duplicates('StudyInstanceUID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:06.365149Z",
     "iopub.status.busy": "2020-10-21T22:26:06.364443Z",
     "iopub.status.idle": "2020-10-21T22:26:07.141907Z",
     "shell.execute_reply": "2020-10-21T22:26:07.140965Z"
    },
    "papermill": {
     "duration": 0.797401,
     "end_time": "2020-10-21T22:26:07.142061",
     "exception": false,
     "start_time": "2020-10-21T22:26:06.344660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: 0.13961847297600685\n",
      "Total scans: 1790594\n",
      "Total positive scans: 96540\n",
      "Max images, positve_count: 250000, 96540\n"
     ]
    }
   ],
   "source": [
    "negative_indices = list(image_labels.loc[image_labels['pe_present_on_image'] == 0].axes[0])\n",
    "positive_indices = list(image_labels.loc[image_labels['pe_present_on_image'] == 1].axes[0])\n",
    "\n",
    "all_indices = negative_indices + positive_indices\n",
    "\n",
    "# ratio of selected max number of images to the total number of images\n",
    "# note that this ratio could be adjusted since the entire dataset is huge\n",
    "ratio = MAX_IMAGES / len(all_indices)\n",
    "\n",
    "positive_count = len(positive_indices)#int(ratio * len(positive_indices))\n",
    "negative_count = MAX_IMAGES - positive_count\n",
    "\n",
    "positive_images = sample(positive_indices, positive_count)\n",
    "negative_images = sample(negative_indices, negative_count)\n",
    "\n",
    "training_indices = list(exam_labels.axes[0])#positive_images + negative_images\n",
    "shuffle(training_indices)\n",
    "\n",
    "# Pick a batch of data indices with a specified number of positive samples\n",
    "def pick_batch(batch_size, positive_count):\n",
    "    #total_positive = batch_size // positive_count\n",
    "    \n",
    "    indices = sample(positive_indices, positive_count) + sample(negative_indices, batch_size - positive_count)\n",
    "    \n",
    "    shuffle(indices)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# Pick a batch of data from all images for validation\n",
    "def pick_validation_batch(batch_size):\n",
    "    indices = sample(all_indices, batch_size)\n",
    "    \n",
    "    shuffle(indices)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "print(\"Ratio:\", ratio)\n",
    "print(\"Total scans:\", len(all_indices))\n",
    "print(\"Total positive scans:\", len(positive_indices))\n",
    "print(f\"Max images, positve_count: {MAX_IMAGES}, {positive_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:07.179480Z",
     "iopub.status.busy": "2020-10-21T22:26:07.177602Z",
     "iopub.status.idle": "2020-10-21T22:26:07.180215Z",
     "shell.execute_reply": "2020-10-21T22:26:07.180706Z"
    },
    "papermill": {
     "duration": 0.028178,
     "end_time": "2020-10-21T22:26:07.180825",
     "exception": false,
     "start_time": "2020-10-21T22:26:07.152647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_scans_from_study(study):\n",
    "    scans = []\n",
    "    fields = []\n",
    "    series = []\n",
    "    for s in os.listdir(TRAIN_ROOT/study):\n",
    "        series.append(s)\n",
    "        scan_set, dcm_fields = load_scans(str(TRAIN_ROOT/study/s))\n",
    "        scans.append(scan_set)\n",
    "        fields.append(dcm_fields)\n",
    "        \n",
    "    return series, scans, fields\n",
    "\n",
    "def load_individual_scan(scan_path):\n",
    "    scan, fields = get_img(scan_path)\n",
    "    scan = rainbow_window(scan, fields)\n",
    "    return scan\n",
    "\n",
    "def load_batch_scans(scan_paths):\n",
    "    scans = np.zeros((len(scan_paths), IMAGE_RESOLUTION[0], IMAGE_RESOLUTION[1], 3))\n",
    "    for i, path in enumerate(scan_paths):\n",
    "        s, f = get_img(path)\n",
    "        s = rainbow_window(s, f)\n",
    "        scans[i] = s\n",
    "        \n",
    "    return scans\n",
    "\n",
    "def batch_images_labels_from_indices(indices):\n",
    "    scan_paths = []\n",
    "    labels = np.array(image_labels['pe_present_on_image'][pd.Index(indices)]).astype(np.int32)\n",
    "    labels = tf.reshape(labels, (batch_size, 1))\n",
    "    for index in indices:\n",
    "        study = image_labels['StudyInstanceUID'][index]\n",
    "        series = image_labels['SeriesInstanceUID'][index]\n",
    "        scan = image_labels['SOPInstanceUID'][index]\n",
    "\n",
    "        scan_paths.append(str(TRAIN_ROOT/('/'.join([study, series, scan+\".dcm\"]))))\n",
    "\n",
    "    scans = augment(load_batch_scans(scan_paths))\n",
    "\n",
    "    return labels, scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:07.281546Z",
     "iopub.status.busy": "2020-10-21T22:26:07.262239Z",
     "iopub.status.idle": "2020-10-21T22:26:14.630328Z",
     "shell.execute_reply": "2020-10-21T22:26:14.629625Z"
    },
    "papermill": {
     "duration": 7.439955,
     "end_time": "2020-10-21T22:26:14.630486",
     "exception": false,
     "start_time": "2020-10-21T22:26:07.190531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 64, 64, 64, 24)    1968      \n",
      "_________________________________________________________________\n",
      "dense_block (DenseBlock)     (None, 64, 64, 64, 216)   347712    \n",
      "_________________________________________________________________\n",
      "transition (Transition)      (None, 32, 32, 32, 108)   24300     \n",
      "_________________________________________________________________\n",
      "dense_block_1 (DenseBlock)   (None, 32, 32, 32, 300)   417600    \n",
      "_________________________________________________________________\n",
      "transition_1 (Transition)    (None, 16, 16, 16, 150)   46350     \n",
      "_________________________________________________________________\n",
      "dense_block_2 (DenseBlock)   (None, 16, 16, 16, 342)   452544    \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 342)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 342)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 3087      \n",
      "=================================================================\n",
      "Total params: 1,293,561\n",
      "Trainable params: 1,270,257\n",
      "Non-trainable params: 23,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_PARAMS = { 'k': 12, 'depth': 100, 'theta': 0.5, 'bottleneck': True }\n",
    "\n",
    "class DenseLayer(layers.Layer):\n",
    "    def __init__(self, k, bottleneck=False):\n",
    "        super(DenseLayer, self).__init__()\n",
    "\n",
    "        self.necked = bottleneck\n",
    "\n",
    "        if bottleneck:\n",
    "            self.bn1 = layers.BatchNormalization()\n",
    "            self.relu1 = layers.ReLU()\n",
    "            self.bottleneck = layers.Conv3D(4*k, 1, padding='same')\n",
    "\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.ReLU()\n",
    "        self.conv = layers.Conv3D(k, 3, padding='same')\n",
    "\n",
    "        if not self.necked:\n",
    "            self.dropout = layers.Dropout(rate=0.2)\n",
    "        self.concat = layers.Concatenate()\n",
    "\n",
    "    def call(self, input_tensor, training):\n",
    "        conv = input_tensor\n",
    "\n",
    "        if self.necked:\n",
    "            conv = self.bn1(conv, training)\n",
    "            conv = self.relu1(conv)\n",
    "            conv = self.bottleneck(conv)\n",
    "\n",
    "        conv = self.bn2(conv, training)\n",
    "        conv = self.relu2(conv)\n",
    "        conv = self.conv(conv)\n",
    "\n",
    "        if not self.necked:\n",
    "            conv = self.dropout(conv, training)\n",
    "        return self.concat([input_tensor, conv])\n",
    "\n",
    "    def build_graph(self, input_shape):\n",
    "        no_batch = input_shape[1:]\n",
    "        self.build(input_shape)\n",
    "\n",
    "        inputs = keras.Input((no_batch))\n",
    "        self.call(inputs)\n",
    "\n",
    "class Transition(layers.Layer):\n",
    "    def __init__(self, input_filters, theta=0.5):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv = layers.Conv3D(int(input_filters*theta), 1, padding='same')\n",
    "        self.pool = layers.AveragePooling3D(2, strides=2)\n",
    "\n",
    "    def call(self, input_tensor, training):\n",
    "        conv = self.bn(input_tensor, training)\n",
    "        conv = self.relu(conv)\n",
    "        conv = self.conv(conv)\n",
    "        return self.pool(conv)\n",
    "\n",
    "class DenseBlock(layers.Layer):\n",
    "    def __init__(self, k, depth, bottleneck):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.lays = []\n",
    "        for i in range(depth):\n",
    "            self.lays.append(DenseLayer(k, bottleneck))\n",
    "\n",
    "    def call(self, input_tensor, training):\n",
    "        conv = input_tensor\n",
    "        for layer in self.lays:\n",
    "            conv = layer(conv, training)\n",
    "\n",
    "        return conv\n",
    "\n",
    "class DenseNet(keras.Model):\n",
    "    def __init__(self, k=DEFAULT_PARAMS['k'],\n",
    "                       depth=DEFAULT_PARAMS['depth'],\n",
    "                       theta=DEFAULT_PARAMS['theta'],\n",
    "                       bottleneck=DEFAULT_PARAMS['bottleneck']):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.conv_init = layers.Conv3D(2*k, 3, padding='same')\n",
    "\n",
    "        if bottleneck:\n",
    "            block_depth = ((depth-3) // 3) // 2\n",
    "        else:\n",
    "            block_depth = (depth-1) // 3\n",
    "\n",
    "        self.block1 = DenseBlock(k, block_depth, bottleneck)\n",
    "        self.trans1 = Transition(2*k + k*block_depth, theta=theta)\n",
    "        self.block2 = DenseBlock(k, block_depth, bottleneck)\n",
    "        self.trans2 = Transition((2*k + k*block_depth)/2 + k*block_depth, theta=theta)\n",
    "        self.block3 = DenseBlock(k, block_depth, bottleneck)\n",
    "        #self.trans3 = Transition((2*k + k*block_depth)/2 + k*block_depth, theta=theta)\n",
    "        #self.block4 = DenseBlock(k, block_depth, bottleneck)\n",
    "        #self.trans4 = Transition((2*k + k*block_depth)/2 + k*block_depth, theta=theta)\n",
    "        #self.block5 = DenseBlock(k, block_depth, bottleneck)\n",
    "        \n",
    "        self.pool = layers.GlobalAveragePooling3D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense = layers.Dense(units=len(exam_label_columns)-1, activation='sigmoid')\n",
    "        \n",
    "        self.build_graph((1, 64, 64, 64, 3))\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        conv = self.conv_init(input_tensor)\n",
    "\n",
    "        conv = self.block1(conv, training)\n",
    "        conv = self.trans1(conv, training)\n",
    "        conv = self.block2(conv, training)\n",
    "        conv = self.trans2(conv, training)\n",
    "        conv = self.block3(conv, training)\n",
    "        #conv = self.trans3(conv, training)\n",
    "        #conv = self.block4(conv, training)\n",
    "        #conv = self.trans4(conv, training)\n",
    "        #conv = self.block5(conv, training)\n",
    "\n",
    "        conv = self.pool(conv)\n",
    "        conv = self.flatten(conv)\n",
    "        return self.dense(conv)\n",
    "\n",
    "    def build_graph(self, input_shape):\n",
    "        input_shape_nobatch = input_shape[1:]\n",
    "        self.build(input_shape)#_nobatch)\n",
    "\n",
    "        inputs = tf.keras.Input(shape=input_shape_nobatch)\n",
    "\n",
    "        if not hasattr(self, 'call'):\n",
    "            raise AttributeError(\"User should define 'call' method in sub-class model!\")\n",
    "\n",
    "        self.__call__(inputs, True)\n",
    "        \n",
    "image_model = DenseNet()\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-21T22:26:14.689394Z",
     "iopub.status.busy": "2020-10-21T22:26:14.680942Z",
     "iopub.status.idle": "2020-10-22T04:23:16.713288Z",
     "shell.execute_reply": "2020-10-22T04:23:16.711104Z"
    },
    "papermill": {
     "duration": 21422.072001,
     "end_time": "2020-10-22T04:23:16.713435",
     "exception": false,
     "start_time": "2020-10-21T22:26:14.641434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4999 of 5000 loss, accuracy: 0.7349879145622253, 0.0      \r"
     ]
    }
   ],
   "source": [
    "# Model definitions\n",
    "keras.backend.clear_session()\n",
    "\n",
    "batch_size = 1\n",
    "image_opt = keras.optimizers.Adam(learning_rate=1e-3, amsgrad=True)\n",
    "\n",
    "loss_weights = np.full((batch_size, 1), len(training_indices)/len(positive_images))\n",
    "\n",
    "def loss_function(labels, logits, weighted=True):\n",
    "    loss = keras.losses.binary_crossentropy(labels, logits, from_logits=True, label_smoothing=0.05)\n",
    "    \n",
    "    if weighted:\n",
    "        weights = tf.cast(tf.math.greater(labels, 0), tf.float32)*loss_weights\n",
    "        weights += tf.cast(tf.math.equal(weights, 0), tf.float32)\n",
    "        weights = tf.reshape(weights, (weights.shape[0],))\n",
    "        \n",
    "        loss = tf.math.multiply(loss, weights)\n",
    "        \n",
    "    print(loss)\n",
    "    assert(False)\n",
    "\n",
    "    loss = tf.math.reduce_mean(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "l = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "#@tf.function\n",
    "def image_train_step(image, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = image_model(image)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(tf.cast(labels, tf.float32), logits)\n",
    "    \n",
    "    gradients = tape.gradient(loss, image_model.trainable_variables)\n",
    "    image_opt.apply_gradients(zip(gradients, image_model.trainable_variables))\n",
    "    \n",
    "    return loss, logits\n",
    "\n",
    "@tf.function\n",
    "def image_validation_step(image, labels):\n",
    "    logits = image_model(image)\n",
    "    loss = loss_function(labels, logits, weighted=False)\n",
    "    \n",
    "    return loss, logits\n",
    "\n",
    "def augment(images):\n",
    "    images = tf.image.random_flip_left_right(images)\n",
    "    images = tf.image.random_flip_up_down(images)\n",
    "    images = tf.image.per_image_standardization(images)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Keeps track of absolute accuracy\n",
    "# i.e. All labels correct => 1,\n",
    "#               otherwise => 0\n",
    "class MultiLabelBinaryAccuracy():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.sum = 0\n",
    "        \n",
    "    # Expecting shapes like [label_count]\n",
    "    def individual_multilabel_accuracy(self, label, logits):\n",
    "        local_count = 0\n",
    "        local_sum = 0\n",
    "        for lab, log in zip(label, logits):\n",
    "            if lab != log:\n",
    "                return 0\n",
    "            \n",
    "        return 1\n",
    "        \n",
    "    # Expecting shapes like [batch_size, label_count]\n",
    "    def __call__(self, labels, logits):\n",
    "        batch_accuracies = []\n",
    "        for i in range(labels.shape[0]):\n",
    "            batch_accuracies.append(self.individual_multilabel_accuracy(labels[i], logits[i]))\n",
    "            \n",
    "        self.sum += tf.math.reduce_mean(batch_accuracies)\n",
    "        self.count += labels.shape[0]\n",
    "        \n",
    "    def result(self):\n",
    "        return self.sum / self.count\n",
    "\n",
    "VALIDATION_STEPS = 500\n",
    "# Run validation every VALIDATION_FREQUENCY train steps\n",
    "VALIDATION_FREQUENCY = 5000\n",
    "\n",
    "loss_met = keras.metrics.Mean()\n",
    "acc_met = MultiLabelBinaryAccuracy()\n",
    "\n",
    "total_iterations = len(training_indices)//batch_size\n",
    "\n",
    "for i in range(TRAIN_STEPS):#range(total_iterations):\n",
    "    indices = sample(training_indices, 1)\n",
    "    train_study = list(train_csv['StudyInstanceUID'][indices])[0]\n",
    "    scans = np.array(load_scans_from_study(train_study)[1])\n",
    "    rescale_factors = (1, 64/scans.shape[1], 64/scans.shape[2], 64/scans.shape[3], 1)\n",
    "    scans = zoom(scans, rescale_factors, order=0)\n",
    "    labels = np.array(exam_labels[exam_label_columns[1:]].loc[indices])\n",
    "    loss, logits = image_train_step(scans, labels)\n",
    "    loss_met(loss)\n",
    "    acc_met(labels, logits)\n",
    "\n",
    "    print(f\"Batch {i} of {TRAIN_STEPS} loss, accuracy: {loss_met.result()}, {acc_met.result()}      \\r\", end='')\n",
    "    \n",
    "image_model.save_weights(\"image_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 21450.075536,
   "end_time": "2020-10-22T04:23:19.706487",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-21T22:25:49.630951",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
